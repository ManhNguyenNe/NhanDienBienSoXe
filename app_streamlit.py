import streamlit as st
import cv2
import numpy as np
from PIL import Image
import tempfile
import os
from ultralytics import YOLO
import easyocr
import plotly.express as px
import pandas as pd

# ================================
# üé® CUSTOM CSS STYLING
# ================================
st.set_page_config(
    page_title="Nh·∫≠n di·ªán bi·ªÉn s·ªë xe",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    /* Main container styling */
    .main {
        padding: 1rem;
    }
    
    /* Custom header */
    .custom-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* Result cards */
    .result-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* Upload area styling */
    .upload-area {
        border: 2px dashed #cccccc;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background-color: #fafafa;
        transition: all 0.3s ease;
    }
    
    .upload-area:hover {
        border-color: #2196F3;
        background-color: #f0f8ff;
    }
    
    /* Hide streamlit footer */
    .css-1d391kg { display: none; }
    footer { display: none; }
    .css-1rs6os { display: none; }
</style>
""", unsafe_allow_html=True)

# ================================
# üöó HEADER SECTION
# ================================
st.markdown("""
<div class="custom-header">
    <h1>üöó Nh·∫≠n di·ªán bi·ªÉn s·ªë xe th√¥ng minh</h1>
    <p style="font-size: 1.2em; margin-top: 1rem;">
        ü§ñ S·ª≠ d·ª•ng YOLOv8 v√† EasyOCR ƒë·ªÉ nh·∫≠n di·ªán bi·ªÉn s·ªë xe
    </p>
</div>
""", unsafe_allow_html=True)

# ================================
# üîß MODEL LOADING
# ================================
@st.cache_resource
def load_models():
    """Load YOLO model and EasyOCR reader"""
    try:
        model = YOLO("runs/weights/best.pt")
        reader = easyocr.Reader(['en'], gpu=True)
        st.success("‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh th√†nh c√¥ng!")
        return model, reader
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}")
        return None, None

model, reader = load_models()

# ================================
# üéõÔ∏è SIDEBAR CONFIGURATION
# ================================
with st.sidebar:
    st.markdown("## üîß C·∫•u h√¨nh")
    
    # Confidence threshold
    confidence_threshold = st.slider(
        "Ng∆∞·ª°ng tin c·∫≠y (%)", 
        min_value=50, 
        max_value=100, 
        value=80,
        help="Ng∆∞·ª°ng tin c·∫≠y t·ªëi thi·ªÉu cho vi·ªác nh·∫≠n di·ªán"
    )
    
    # Show details option
    show_details = st.checkbox("üìà Hi·ªÉn th·ªã chi ti·∫øt k·∫øt qu·∫£", value=True)
    
    # About section
    st.markdown("### ‚ÑπÔ∏è Gi·ªõi thi·ªáu")
    st.markdown("""
    **C√¥ng ngh·ªá s·ª≠ d·ª•ng:**
    - ü§ñ **YOLOv8**: Nh·∫≠n di·ªán v·ªã tr√≠ bi·ªÉn s·ªë
    - üìù **EasyOCR**: ƒê·ªçc k√Ω t·ª± tr√™n bi·ªÉn s·ªë
    - üéØ **ƒê·ªô ch√≠nh x√°c**: >90%
    """)

# ================================
# üõ†Ô∏è HELPER FUNCTIONS
# ================================
def order_points(pts):
    """S·∫Øp x·∫øp c√°c ƒëi·ªÉm theo th·ª© t·ª±: tr√™n-tr√°i, tr√™n-ph·∫£i, d∆∞·ªõi-ph·∫£i, d∆∞·ªõi-tr√°i"""
    rect = np.zeros((4, 2), dtype=np.float32)
    
    # T·ªïng t·ªça ƒë·ªô (x,y) nh·ªè nh·∫•t l√† ƒëi·ªÉm tr√™n-tr√°i
    # T·ªïng t·ªça ƒë·ªô (x,y) l·ªõn nh·∫•t l√† ƒëi·ªÉm d∆∞·ªõi-ph·∫£i
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    
    # Hi·ªáu t·ªça ƒë·ªô (x-y) nh·ªè nh·∫•t l√† ƒëi·ªÉm tr√™n-ph·∫£i
    # Hi·ªáu t·ªça ƒë·ªô (x-y) l·ªõn nh·∫•t l√† ƒëi·ªÉm d∆∞·ªõi-tr√°i
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    
    return rect

def four_point_transform(image, pts):
    """Th·ª±c hi·ªán bi·∫øn ƒë·ªïi ph·ªëi c·∫£nh 4 ƒëi·ªÉm"""
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    
    # T√≠nh chi·ªÅu r·ªông m·ªõi
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))
    
    # T√≠nh chi·ªÅu cao m·ªõi
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))
    
    # T·∫°o ma tr·∫≠n ƒëi·ªÉm ƒë√≠ch
    dst = np.array([
        [0, 0],
        [maxWidth - 1, 0],
        [maxWidth - 1, maxHeight - 1],
        [0, maxHeight - 1]
    ], dtype=np.float32)
    
    # T√≠nh ma tr·∫≠n bi·∫øn ƒë·ªïi v√† th·ª±c hi·ªán bi·∫øn ƒë·ªïi
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))
    
    return warped

def process_image(image):
    """Process image and return results"""
    # Convert PIL Image to numpy array
    image_np = np.array(image)
    # Convert RGB to BGR (OpenCV format)
    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    
    # Detect license plates
    results = model(image_bgr)
    boxes = results[0].boxes.xyxy.cpu().numpy()
    confidences = results[0].boxes.conf.cpu().numpy()
    
    # Process each detected plate
    plates = []
    for box, conf in zip(boxes, confidences):
        if conf * 100 >= confidence_threshold:
            x1, y1, x2, y2 = map(int, box)
            
            # C·∫Øt bi·ªÉn s·ªë xe t·ª´ ·∫£nh g·ªëc
            cropped_plate = image_bgr[y1:y2, x1:x2]
            
            # Th·ª±c hi·ªán ph·ªëi c·∫£nh 4 g√≥c
            corners = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]], dtype=np.float32)
            warped_plate = four_point_transform(image_bgr, corners)
            
            # Resize ƒë·ªÉ tƒÉng k√≠ch th∆∞·ªõc
            warped_plate = cv2.resize(warped_plate, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
            
            # Chuy·ªÉn sang grayscale
            gray_plate = cv2.cvtColor(warped_plate, cv2.COLOR_BGR2GRAY)
            
            # TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n b·∫±ng CLAHE
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced_plate = clahe.apply(gray_plate)
            
            # Chuy·ªÉn ƒë·ªïi t·ª´ BGR sang RGB ƒë·ªÉ hi·ªÉn th·ªã
            processed_plate_rgb = cv2.cvtColor(enhanced_plate, cv2.COLOR_GRAY2RGB)
            
            # Th·ª±c hi·ªán OCR tr√™n ·∫£nh ƒë√£ x·ª≠ l√Ω
            ocr_results = reader.readtext(enhanced_plate, allowlist='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ-')
            
            # T√≠nh to√°n ƒë·ªô tin c·∫≠y trung b√¨nh c·ªßa OCR
            ocr_confidences = [conf for (_, _, conf) in ocr_results]
            avg_ocr_confidence = sum(ocr_confidences) / len(ocr_confidences) if ocr_confidences else 0
            
            plate_text = " ".join([text for (_, text, _) in ocr_results])
            
            # V·∫Ω box v√† text l√™n ·∫£nh g·ªëc v·ªõi c·∫£ hai ƒë·ªô tin c·∫≠y
            cv2.rectangle(image_bgr, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            plates.append({
                'text': plate_text,
                'box': (x1, y1, x2, y2),
                'image': processed_plate_rgb,  # ·∫¢nh ƒë√£ x·ª≠ l√Ω ho√†n ch·ªânh
                'cropped_image': cv2.cvtColor(cropped_plate, cv2.COLOR_BGR2RGB),  # ·∫¢nh c·∫Øt th√¥ng th∆∞·ªùng
                'detect_confidence': conf * 100,
                'ocr_confidence': avg_ocr_confidence * 100
            })
    
    # Convert BGR back to RGB for display
    result_image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    return result_image, plates

# ================================
# üì§ FILE UPLOAD SECTION
# ================================
st.markdown("## üì§ T·∫£i l√™n ·∫£nh")

uploaded_file = st.file_uploader(
    "Ch·ªçn ·∫£nh ƒë·ªÉ ph√¢n t√≠ch",
    type=["jpg", "jpeg", "png"],
    help="H·ªó tr·ª£: JPG, PNG. K√≠ch th∆∞·ªõc t·ªëi ƒëa: 10MB"
)

if uploaded_file is not None:
    # Display original image
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### üñºÔ∏è ·∫¢nh g·ªëc")
        image = Image.open(uploaded_file)
        st.image(image, caption='·∫¢nh ƒë√£ t·∫£i l√™n', use_container_width=True)
        
        # Image info
        width, height = image.size
        st.info(f"üìê K√≠ch th∆∞·ªõc: {width} x {height} pixels")
    
    with col2:
        st.markdown("### üîç K·∫øt qu·∫£ ph√¢n t√≠ch")
        
        if st.button("üöÄ B·∫Øt ƒë·∫ßu ph√¢n t√≠ch", type="primary", use_container_width=True):
            with st.spinner('ü§ñ AI ƒëang ph√¢n t√≠ch...'):
                try:
                    # Process image
                    result_image, plates = process_image(image)
                    
                    # Display result image
                    st.image(result_image, caption='K·∫øt qu·∫£ nh·∫≠n di·ªán', use_container_width=True)
                    
                    # Display detected plates
                    if plates:
                        st.success(f"‚úÖ ƒê√£ ph√°t hi·ªán {len(plates)} bi·ªÉn s·ªë xe!")
                        
                        for i, plate in enumerate(plates, 1):
                            # T·∫°o 3 c·ªôt ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£
                            plate_col1, plate_col2, plate_col3 = st.columns(3)
                            
                            with plate_col1:
                                st.image(plate['cropped_image'], caption=f'Bi·ªÉn s·ªë #{i} (·∫¢nh c·∫Øt th√¥ng th∆∞·ªùng)', use_container_width=True)
                            
                            with plate_col2:
                                st.image(plate['image'], caption=f'Bi·ªÉn s·ªë #{i} (·∫¢nh ƒë√£ x·ª≠ l√Ω)', use_container_width=True)
                            
                            with plate_col3:
                                st.markdown(f"""
                                <div class="result-card">
                                    <h3>Bi·ªÉn s·ªë #{i}</h3>
                                    <h2 style="font-size: 2em; margin: 10px 0;">{plate['text']}</h2>
                                    <div style="margin: 15px 0;">
                                        <p style="font-size: 1.1em;">üìä ƒê·ªô tin c·∫≠y:</p>
                                        <p>ü§ñ Model ph√°t hi·ªán: {plate['detect_confidence']:.1f}%</p>
                                        <p>üìù Model OCR: {plate['ocr_confidence']:.1f}%</p>
                                    </div>
                                </div>
                                """, unsafe_allow_html=True)
                            
                            if show_details:
                                st.markdown("---")
                    else:
                        st.warning(f"‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán bi·ªÉn s·ªë xe n√†o v·ªõi ng∆∞·ª°ng tin c·∫≠y {confidence_threshold}%!")
                    
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi ph√¢n t√≠ch: {str(e)}")

# ================================
# üìä FOOTER STATISTICS
# ================================
st.markdown("---")
st.markdown("### üìà Th·ªëng k√™ h·ªá th·ªëng")

col1, col2, col3 = st.columns(3)

with col1:
    st.metric("ü§ñ M√¥ h√¨nh", "YOLOv8 + EasyOCR")

with col2:
    st.metric("üéØ ƒê·ªô ch√≠nh x√°c", ">90%")

with col3:
    st.metric("‚ö° T·ªëc ƒë·ªô x·ª≠ l√Ω", "~1.5s/·∫£nh")

# Add footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 2rem;'>
    <p>üöó <strong>Nh·∫≠n di·ªán bi·ªÉn s·ªë xe th√¥ng minh</strong> - ƒê∆∞·ª£c ph√°t tri·ªÉn v·ªõi ‚ù§Ô∏è b·∫±ng Streamlit & YOLOv8</p>
    <p>ü§ñ Nh·∫≠n di·ªán bi·ªÉn s·ªë ch√≠nh x√°c ‚Ä¢ üìä X·ª≠ l√Ω ·∫£nh nhanh ch√≥ng ‚Ä¢ üîí B·∫£o m·∫≠t d·ªØ li·ªáu</p>
</div>
""", unsafe_allow_html=True) 