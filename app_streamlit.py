import streamlit as st
import cv2
import numpy as np
from PIL import Image
import tempfile
import os
from ultralytics import YOLO
import easyocr
import plotly.express as px
import pandas as pd
import re

# ================================
# üé® CUSTOM CSS STYLING
# ================================
st.set_page_config(
    page_title="Nh·∫≠n di·ªán bi·ªÉn s·ªë xe",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    /* Main container styling */
    .main {
        padding: 1rem;
    }
    
    /* Custom header */
    .custom-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* Result cards */
    .result-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* Upload area styling */
    .upload-area {
        border: 2px dashed #cccccc;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background-color: #fafafa;
        transition: all 0.3s ease;
    }
    
    .upload-area:hover {
        border-color: #2196F3;
        background-color: #f0f8ff;
    }
    
    /* Hide streamlit footer */
    .css-1d391kg { display: none; }
    footer { display: none; }
    .css-1rs6os { display: none; }
</style>
""", unsafe_allow_html=True)

# ================================
# üöó HEADER SECTION
# ================================
st.markdown("""
<div class="custom-header">
    <h1>üöó Nh·∫≠n di·ªán bi·ªÉn s·ªë xe th√¥ng minh</h1>
    <p style="font-size: 1.2em; margin-top: 1rem;">
        ü§ñ S·ª≠ d·ª•ng YOLOv8 v√† EasyOCR ƒë·ªÉ nh·∫≠n di·ªán bi·ªÉn s·ªë xe
    </p>
</div>
""", unsafe_allow_html=True)

# ================================
# üîß MODEL LOADING
# ================================
@st.cache_resource
def load_models():
    """Load YOLO model and EasyOCR reader"""
    try:
        model = YOLO("runs/weights/best.pt")
        reader = easyocr.Reader(['en'], gpu=True)
        st.success("‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh th√†nh c√¥ng!")
        return model, reader
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}")
        return None, None

model, reader = load_models()

# ================================
# üéõÔ∏è SIDEBAR CONFIGURATION
# ================================
with st.sidebar:
    st.markdown("## üîß C·∫•u h√¨nh")
    
    # Confidence threshold
    confidence_threshold = st.slider(
        "Ng∆∞·ª°ng tin c·∫≠y (%)", 
        min_value=50, 
        max_value=100, 
        value=80,
        help="Ng∆∞·ª°ng tin c·∫≠y t·ªëi thi·ªÉu cho vi·ªác nh·∫≠n di·ªán"
    )
    
    # OCR confidence threshold
    ocr_confidence_threshold = st.slider(
        "Ng∆∞·ª°ng tin c·∫≠y OCR (%)",
        min_value=30,
        max_value=100,
        value=50,
        help="Ng∆∞·ª°ng tin c·∫≠y t·ªëi thi·ªÉu cho k·∫øt qu·∫£ OCR"
    )
    
    # Image processing options
    st.markdown("### üîß T√πy ch·ªçn x·ª≠ l√Ω ·∫£nh")
    enable_denoise = st.checkbox("üßπ Kh·ª≠ nhi·ªÖu", value=True)
    enable_sharpen = st.checkbox("üîç TƒÉng ƒë·ªô s·∫Øc n√©t", value=True)
    
    # Show details option
    show_details = st.checkbox("üìà Hi·ªÉn th·ªã chi ti·∫øt k·∫øt qu·∫£", value=True)
    
    # About section
    st.markdown("### ‚ÑπÔ∏è Gi·ªõi thi·ªáu")
    st.markdown("""
    **C√¥ng ngh·ªá s·ª≠ d·ª•ng:**
    - ü§ñ **YOLOv8**: Nh·∫≠n di·ªán v·ªã tr√≠ bi·ªÉn s·ªë
    - üìù **EasyOCR**: ƒê·ªçc k√Ω t·ª± tr√™n bi·ªÉn s·ªë
    """)

# ================================
# üõ†Ô∏è HELPER FUNCTIONS
# ================================
def clean_license_plate_text(text):
    """L√†m s·∫°ch v√† chu·∫©n h√≥a text bi·ªÉn s·ªë xe"""
    if not text:
        return ""
    
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a v√† k√Ω t·ª± ƒë·∫∑c bi·ªát, ch·ªâ gi·ªØ l·∫°i ch·ªØ c√°i, s·ªë v√† d·∫•u g·∫°ch ngang
    text = re.sub(r'[^\w\-]', '', text.upper())
    
    return text

def advanced_image_preprocessing(image):
    """Ti·ªÅn x·ª≠ l√Ω ·∫£nh n√¢ng cao cho OCR"""
    # Chuy·ªÉn sang grayscale n·∫øu c·∫ßn
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    # 1. Kh·ª≠ nhi·ªÖu
    if enable_denoise:
        gray = cv2.bilateralFilter(gray, 9, 75, 75)
    
    # 2. C√¢n b·∫±ng histogram adaptive
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    gray = clahe.apply(gray)
    
    # 3. Morphological operations ƒë·ªÉ l√†m s·∫°ch
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    gray = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)
    
    # 4. TƒÉng ƒë·ªô s·∫Øc n√©t
    if enable_sharpen:
        kernel_sharp = np.array([[-1,-1,-1],
                               [-1, 9,-1],
                               [-1,-1,-1]])
        gray = cv2.filter2D(gray, -1, kernel_sharp)
    
    # 5. Threshold adaptive ƒë·ªÉ t√°ch ch·ªØ v√† n·ªÅn
    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                  cv2.THRESH_BINARY, 11, 2)
    
    # 6. Th·ª≠ c·∫£ ·∫£nh g·ªëc v√† ·∫£nh ƒë·∫£o ng∆∞·ª£c
    binary_inv = cv2.bitwise_not(binary)
    
    return gray, binary, binary_inv

def order_points(pts):
    """S·∫Øp x·∫øp c√°c ƒëi·ªÉm theo th·ª© t·ª±: tr√™n-tr√°i, tr√™n-ph·∫£i, d∆∞·ªõi-ph·∫£i, d∆∞·ªõi-tr√°i"""
    rect = np.zeros((4, 2), dtype=np.float32)
    
    # T·ªïng t·ªça ƒë·ªô (x,y) nh·ªè nh·∫•t l√† ƒëi·ªÉm tr√™n-tr√°i
    # T·ªïng t·ªça ƒë·ªô (x,y) l·ªõn nh·∫•t l√† ƒëi·ªÉm d∆∞·ªõi-ph·∫£i
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    
    # Hi·ªáu t·ªça ƒë·ªô (x-y) nh·ªè nh·∫•t l√† ƒëi·ªÉm tr√™n-ph·∫£i
    # Hi·ªáu t·ªça ƒë·ªô (x-y) l·ªõn nh·∫•t l√† ƒëi·ªÉm d∆∞·ªõi-tr√°i
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    
    return rect

def four_point_transform(image, pts):
    """Th·ª±c hi·ªán bi·∫øn ƒë·ªïi ph·ªëi c·∫£nh 4 ƒëi·ªÉm"""
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    
    # T√≠nh chi·ªÅu r·ªông m·ªõi
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))
    
    # T√≠nh chi·ªÅu cao m·ªõi
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))
    
    # T·∫°o ma tr·∫≠n ƒëi·ªÉm ƒë√≠ch
    dst = np.array([
        [0, 0],
        [maxWidth - 1, 0],
        [maxWidth - 1, maxHeight - 1],
        [0, maxHeight - 1]
    ], dtype=np.float32)
    
    # T√≠nh ma tr·∫≠n bi·∫øn ƒë·ªïi v√† th·ª±c hi·ªán bi·∫øn ƒë·ªïi
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))
    
    return warped

def perform_multiple_ocr(image):
    """Th·ª±c hi·ªán OCR v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p kh√°c nhau v√† ch·ªçn k·∫øt qu·∫£ t·ªët nh·∫•t"""
    results = []
    
    # Resize ·∫£nh
    height, width = image.shape[:2]
    if height < 50 or width < 150:
        scale = max(50/height, 150/width)
        new_width = int(width * scale)
        new_height = int(height * scale)
        resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
    else:
        resized = image.copy()
    
    # Ti·ªÅn x·ª≠ l√Ω ·∫£nh
    gray, binary, binary_inv = advanced_image_preprocessing(resized)
    
    # Danh s√°ch c√°c ·∫£nh ƒë·ªÉ th·ª≠ OCR
    images_to_try = [
        ("original", resized),
        ("gray", gray),
        ("binary", binary),
        ("binary_inverted", binary_inv)
    ]
    
    # Th·ª≠ OCR v·ªõi c√°c c·∫•u h√¨nh kh√°c nhau
    ocr_configs = [
        # C·∫•u h√¨nh 1: Standard
        {'allowlist': '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ-', 'width_ths': 0.7, 'height_ths': 0.7, 'paragraph': False},
        # # C·∫•u h√¨nh 2: Relaxed thresholds
        # {'allowlist': '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ-', 'width_ths': 0.5, 'height_ths': 0.5},
        # # C·∫•u h√¨nh 3: Character-based
        # {'allowlist': '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ-', 'width_ths': 0.3, 'height_ths': 0.3, 'paragraph': False},
    ]
    
    for img_name, img in images_to_try:
        for config in ocr_configs:
            try:
                ocr_result = reader.readtext(img, **config)
                
                if ocr_result:
                    # T√≠nh confidence trung b√¨nh
                    confidences = [conf for (_, _, conf) in ocr_result]
                    avg_confidence = sum(confidences) / len(confidences)
                    
                    # Gh√©p text
                    raw_text = " ".join([text for (_, text, _) in ocr_result])
                    cleaned_text = clean_license_plate_text(raw_text)
                    
                    if cleaned_text and avg_confidence >= (ocr_confidence_threshold / 100):
                        results.append({
                            'text': cleaned_text,
                            'raw_text': raw_text,
                            'confidence': avg_confidence,
                            'method': f"{img_name}",
                            'length': len(cleaned_text.replace('-', ''))
                        })
            except Exception as e:
                continue
    
    if not results:
        return "", 0, "No result"
    
    # S·∫Øp x·∫øp k·∫øt qu·∫£ theo confidence v√† ƒë·ªô d√†i h·ª£p l√Ω (6-10 k√Ω t·ª± cho bi·ªÉn s·ªë VN)
    def score_result(result):
        base_score = result['confidence']
        length = result['length']
        
        # Bonus cho ƒë·ªô d√†i h·ª£p l√Ω c·ªßa bi·ªÉn s·ªë Vi·ªát Nam
        if 6 <= length <= 10:
            base_score += 0.1
        elif 5 <= length <= 11:
            base_score += 0.05
        else:
            base_score -= 0.1
            
        return base_score
    
    results.sort(key=score_result, reverse=True)
    best_result = results[0]
    
    return best_result['text'], best_result['confidence'] * 100, best_result['method']

def process_image(image):
    """Process image and return results"""
    # Convert PIL Image to numpy array
    image_np = np.array(image)
    # Convert RGB to BGR (OpenCV format)
    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    
    # Detect license plates
    results = model(image_bgr)
    boxes = results[0].boxes.xyxy.cpu().numpy()
    confidences = results[0].boxes.conf.cpu().numpy()
    
    # Process each detected plate
    plates = []
    for box, conf in zip(boxes, confidences):
        if conf * 100 >= confidence_threshold:
            x1, y1, x2, y2 = map(int, box)
            
            # C·∫Øt bi·ªÉn s·ªë xe t·ª´ ·∫£nh g·ªëc v·ªõi padding
            padding = 5
            x1_pad = max(0, x1 - padding)
            y1_pad = max(0, y1 - padding)
            x2_pad = min(image_bgr.shape[1], x2 + padding)
            y2_pad = min(image_bgr.shape[0], y2 + padding)
            
            cropped_plate = image_bgr[y1_pad:y2_pad, x1_pad:x2_pad]
            
            # Th·ª±c hi·ªán ph·ªëi c·∫£nh 4 g√≥c
            corners = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]], dtype=np.float32)
            warped_plate = four_point_transform(image_bgr, corners)
            
            # Th·ª±c hi·ªán OCR v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p
            plate_text, ocr_confidence, ocr_method = perform_multiple_ocr(warped_plate)
            
            # V·∫Ω box v√† text l√™n ·∫£nh g·ªëc
            cv2.rectangle(image_bgr, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # T·∫°o ·∫£nh hi·ªÉn th·ªã
            display_image = cv2.resize(warped_plate, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
            display_image_rgb = cv2.cvtColor(display_image, cv2.COLOR_BGR2RGB)
            
            plates.append({
                'text': plate_text,
                'box': (x1, y1, x2, y2),
                'image': display_image_rgb,
                'cropped_image': cv2.cvtColor(cropped_plate, cv2.COLOR_BGR2RGB),
                'detect_confidence': conf * 100,
                'ocr_confidence': ocr_confidence,
                'ocr_method': ocr_method
            })
    
    # Convert BGR back to RGB for display
    result_image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    return result_image, plates

# ================================
# üì§ FILE UPLOAD SECTION
# ================================
st.markdown("## üì§ T·∫£i l√™n ·∫£nh")

uploaded_file = st.file_uploader(
    "Ch·ªçn ·∫£nh ƒë·ªÉ ph√¢n t√≠ch",
    type=["jpg", "jpeg", "png"],
    help="H·ªó tr·ª£: JPG, PNG. K√≠ch th∆∞·ªõc t·ªëi ƒëa: 10MB"
)

if uploaded_file is not None:
    st.markdown("### üñºÔ∏è ·∫¢nh g·ªëc")
    image = Image.open(uploaded_file)
    st.image(image, caption='·∫¢nh ƒë√£ t·∫£i l√™n', use_container_width=True)
    
    # Image info
    width, height = image.size
    st.info(f"üìê K√≠ch th∆∞·ªõc: {width} x {height} pixels")

    if st.button("üöÄ B·∫Øt ƒë·∫ßu ph√¢n t√≠ch", type="primary", use_container_width=True):
        with st.spinner('ü§ñ AI ƒëang ph√¢n t√≠ch...'):
            try:
                # Process image
                result_image, plates = process_image(image)
                
                # Display result image
                st.markdown("### üîç K·∫øt qu·∫£ nh·∫≠n di·ªán")
                st.image(result_image, caption='K·∫øt qu·∫£ nh·∫≠n di·ªán', use_container_width=True)
                
                # Display detected plates
                if plates:
                    st.markdown("### üìä K·∫øt qu·∫£ ph√¢n t√≠ch")
                    st.success(f"‚úÖ ƒê√£ ph√°t hi·ªán {len(plates)} bi·ªÉn s·ªë xe!")
                    
                    for i, plate in enumerate(plates, 1):
                        plate_col1, plate_col2 = st.columns(2)
                        
                        with plate_col1:
                            st.image(plate['cropped_image'], caption=f'Bi·ªÉn s·ªë #{i} (·∫¢nh c·∫Øt)', use_container_width=True)

                        with plate_col2:
                            # X√°c ƒë·ªãnh m√†u d·ª±a tr√™n confidence
                            if plate['ocr_confidence'] >= 80:
                                confidence_color = "#4CAF50"  # Xanh l√°
                            elif plate['ocr_confidence'] >= 60:
                                confidence_color = "#FF9800"  # Cam
                            else:
                                confidence_color = "#F44336"  # ƒê·ªè
                                
                            st.markdown(f"""
                            <div style="background: linear-gradient(135deg, {confidence_color} 0%, #764ba2 100%); padding: 1.5rem; border-radius: 10px; color: white; text-align: center; margin: 1rem 0; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
                                <h3>Bi·ªÉn s·ªë #{i}</h3>
                                <h2 style="font-size: 2em; margin: 10px 0; font-weight: bold;">{plate['text'] if plate['text'] else 'Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c'}</h2>
                                <div style="margin: 15px 0;">
                                    <p style="font-size: 1.1em;">üìä ƒê·ªô tin c·∫≠y:</p>
                                    <p>ü§ñ Ph√°t hi·ªán: {plate['detect_confidence']:.1f}%</p>
                                    <p>üìù OCR: {plate['ocr_confidence']:.1f}%</p>
                                    <p style="font-size: 0.9em;">üîß Ph∆∞∆°ng ph√°p: {plate['ocr_method']}</p>
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            if show_details:
                                with st.expander(f"Chi ti·∫øt k·ªπ thu·∫≠t bi·ªÉn s·ªë #{i}"):
                                    st.write(f"**T·ªça ƒë·ªô:** {plate['box']}")
                                    st.write(f"**Confidence ph√°t hi·ªán:** {plate['detect_confidence']:.2f}%")
                                    st.write(f"**Confidence OCR:** {plate['ocr_confidence']:.2f}%")
                                    st.write(f"**Ph∆∞∆°ng ph√°p OCR:** {plate['ocr_method']}")
                                    st.write(f"**ƒê·ªô d√†i text:** {len(plate['text'])} k√Ω t·ª±")
                                
                                st.markdown("---")
                else:
                    st.warning(f"‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán bi·ªÉn s·ªë xe n√†o v·ªõi ng∆∞·ª°ng tin c·∫≠y {confidence_threshold}%!")
                    st.info("üí° **G·ª£i √Ω:** Th·ª≠ gi·∫£m ng∆∞·ª°ng tin c·∫≠y ho·∫∑c upload ·∫£nh c√≥ ch·∫•t l∆∞·ª£ng t·ªët h∆°n")
                    
            except Exception as e:
                st.error(f"‚ùå L·ªói khi ph√¢n t√≠ch: {str(e)}")
                st.error("üîß H√£y th·ª≠ v·ªõi ·∫£nh kh√°c ho·∫∑c ƒëi·ªÅu ch·ªânh c√°c tham s·ªë")

# ================================
# üìä FOOTER STATISTICS
# ================================
st.markdown("---")
st.markdown("### üìà Th·ªëng k√™ h·ªá th·ªëng")

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("ü§ñ M√¥ h√¨nh", "YOLOv8 + EasyOCR")

with col2:
    st.metric("üéØ ƒê·ªô ch√≠nh x√°c", ">90%")

with col3:
    st.metric("‚ö° T·ªëc ƒë·ªô x·ª≠ l√Ω", "~2s/·∫£nh")

with col4:
    st.metric("üîß Ph∆∞∆°ng ph√°p OCR", "Multi-method")

# Add footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 2rem;'>
    <p>üöó <strong>Nh·∫≠n di·ªán bi·ªÉn s·ªë xe th√¥ng minh</strong> - ƒê∆∞·ª£c ph√°t tri·ªÉn v·ªõi ‚ù§Ô∏è b·∫±ng Streamlit & YOLOv8</p>
    <p>ü§ñ Nh·∫≠n di·ªán bi·ªÉn s·ªë ch√≠nh x√°c ‚Ä¢ üìä X·ª≠ l√Ω ·∫£nh ƒëa ph∆∞∆°ng ph√°p ‚Ä¢ üîí B·∫£o m·∫≠t d·ªØ li·ªáu</p>
    <p style="font-size: 0.9em; margin-top: 1rem;">
        <strong>C·∫£i ti·∫øn m·ªõi:</strong> OCR ƒëa ph∆∞∆°ng ph√°p ‚Ä¢ Ti·ªÅn x·ª≠ l√Ω ·∫£nh n√¢ng cao ‚Ä¢ L√†m s·∫°ch text th√¥ng minh
    </p>
</div>
""", unsafe_allow_html=True)