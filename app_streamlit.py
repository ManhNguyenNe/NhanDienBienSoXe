import streamlit as st
import cv2
import numpy as np
from PIL import Image
import tempfile
import os
from ultralytics import YOLO
import easyocr
import plotly.express as px
import pandas as pd
import re

# ================================
# üé® CUSTOM CSS STYLING
# ================================
st.set_page_config(
    page_title="Nh·∫≠n di·ªán bi·ªÉn s·ªë xe",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    /* Main container styling */
    .main {
        padding: 1rem;
    }
    
    /* Custom header */
    .custom-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* Result cards */
    .result-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* Upload area styling */
    .upload-area {
        border: 2px dashed #cccccc;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background-color: #fafafa;
        transition: all 0.3s ease;
    }
    
    .upload-area:hover {
        border-color: #2196F3;
        background-color: #f0f8ff;
    }
    
    /* Hide streamlit footer */
    .css-1d391kg { display: none; }
    footer { display: none; }
    .css-1rs6os { display: none; }
</style>
""", unsafe_allow_html=True)

# ================================
# üöó HEADER SECTION
# ================================
st.markdown("""
<div class="custom-header">
    <h1>üöó Nh·∫≠n di·ªán bi·ªÉn s·ªë xe th√¥ng minh</h1>
    <p style="font-size: 1.2em; margin-top: 1rem;">
        ü§ñ S·ª≠ d·ª•ng YOLOv8 v√† EasyOCR ƒë·ªÉ nh·∫≠n di·ªán bi·ªÉn s·ªë xe
    </p>
</div>
""", unsafe_allow_html=True)

# ================================
# üîß MODEL LOADING
# ================================
@st.cache_resource
def load_models():
    """Load YOLO model and EasyOCR reader"""
    try:
        model = YOLO("runs/weights/best.pt")
        # T·ªëi ∆∞u EasyOCR cho ti·∫øng Vi·ªát v√† ti·∫øng Anh
        reader = easyocr.Reader(['en'], gpu=True)
        st.success("‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh th√†nh c√¥ng!")
        return model, reader
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}")
        return None, None

model, reader = load_models()

# ================================
# üéõÔ∏è SIDEBAR CONFIGURATION
# ================================
with st.sidebar:
    st.markdown("## üîß C·∫•u h√¨nh")
    
    # Confidence threshold
    confidence_threshold = st.slider(
        "Ng∆∞·ª°ng tin c·∫≠y (%)", 
        min_value=50, 
        max_value=100, 
        value=80,
        help="Ng∆∞·ª°ng tin c·∫≠y t·ªëi thi·ªÉu cho vi·ªác nh·∫≠n di·ªán"
    )
    
    # OCR confidence threshold
    ocr_confidence_threshold = st.slider(
        "Ng∆∞·ª°ng tin c·∫≠y OCR (%)",
        min_value=30,
        max_value=100,
        value=50,
        help="Ng∆∞·ª°ng tin c·∫≠y t·ªëi thi·ªÉu cho k·∫øt qu·∫£ OCR"
    )
    
    # Image processing options
    st.markdown("### üîß T√πy ch·ªçn x·ª≠ l√Ω ·∫£nh")
    enable_denoise = st.checkbox("üßπ Kh·ª≠ nhi·ªÖu", value=True)
    enable_sharpen = st.checkbox("üîç TƒÉng ƒë·ªô s·∫Øc n√©t", value=True)
    resize_factor = st.slider("üìè H·ªá s·ªë ph√≥ng to", 1.5, 4.0, 2.5, 0.5)
    
    # Show details option
    show_details = st.checkbox("üìà Hi·ªÉn th·ªã chi ti·∫øt k·∫øt qu·∫£", value=True)
    
    # About section
    st.markdown("### ‚ÑπÔ∏è Gi·ªõi thi·ªáu")
    st.markdown("""
    **C√¥ng ngh·ªá s·ª≠ d·ª•ng:**
    - ü§ñ **YOLOv8**: Nh·∫≠n di·ªán v·ªã tr√≠ bi·ªÉn s·ªë
    - üìù **EasyOCR**: ƒê·ªçc k√Ω t·ª± tr√™n bi·ªÉn s·ªë
    - üéØ **ƒê·ªô ch√≠nh x√°c**: >90%
    """)

# ================================
# üõ†Ô∏è HELPER FUNCTIONS
# ================================
def clean_license_plate_text(text):
    """L√†m s·∫°ch v√† chu·∫©n h√≥a text bi·ªÉn s·ªë xe"""
    if not text:
        return ""
    
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a v√† k√Ω t·ª± ƒë·∫∑c bi·ªát
    text = re.sub(r'[^\w\-]', '', text.upper())
    
    # T√°ch ph·∫ßn ch·ªØ v√† s·ªë
    parts = []
    current_part = ""
    prev_type = None
    
    for char in text:
        if char.isdigit():
            char_type = "digit"
        elif char.isalpha():
            char_type = "alpha"
        else:
            continue
            
        if prev_type and prev_type != char_type:
            if current_part:
                parts.append(current_part)
            current_part = char
        else:
            current_part += char
            
        prev_type = char_type
    
    if current_part:
        parts.append(current_part)
    
    # X·ª≠ l√Ω t·ª´ng ph·∫ßn m·ªôt c√°ch th√¥ng minh
    cleaned_parts = []
    for i, part in enumerate(parts):
        if part.isalpha():
            # Ph·∫ßn ch·ªØ c√°i: gi·ªØ nguy√™n, ch·ªâ s·ª≠a nh·ªØng tr∆∞·ªùng h·ª£p r√µ r√†ng
            cleaned_part = smart_clean_alpha_part(part, is_first_part=(i == 0))
        else:
            # Ph·∫ßn s·ªë: thay th·∫ø nh·ªØng k√Ω t·ª± r√µ r√†ng b·ªã OCR nh·∫ßm
            cleaned_part = smart_clean_numeric_part(part)
        
        if cleaned_part:
            cleaned_parts.append(cleaned_part)
    
    return "".join(cleaned_parts)

def smart_clean_alpha_part(text, is_first_part=False):
    """L√†m s·∫°ch ph·∫ßn ch·ªØ c√°i m·ªôt c√°ch th√¥ng minh"""
    result = ""
    
    for i, char in enumerate(text):
        # Ch·ªâ thay th·∫ø khi c√≥ b·∫±ng ch·ª©ng r√µ r√†ng l√† OCR nh·∫ßm
        if char == 'O' and i > 0 and text[i-1].isalpha():
            # O ·ªü gi·ªØa/cu·ªëi t·ª´ c√≥ th·ªÉ l√† s·ªë 0
            if is_surrounded_by_numbers_context(text, i):
                result += '0'
            else:
                result += char
        elif char == 'I' and len(text) > 2 and not is_first_part:
            # I trong ph·∫ßn kh√¥ng ph·∫£i ƒë·∫ßu ti√™n c√≥ th·ªÉ l√† s·ªë 1
            result += '1'
        elif char in ['Q', 'D'] and is_likely_zero_context(text, i):
            # Q, D c√≥ th·ªÉ l√† 0 trong context nh·∫•t ƒë·ªãnh
            result += '0'
        else:
            result += char
    
    return result

def smart_clean_numeric_part(text):
    """L√†m s·∫°ch ph·∫ßn s·ªë m·ªôt c√°ch th√¥ng minh"""
    result = ""
    
    for i, char in enumerate(text):
        if char.isdigit():
            result += char
        elif char in ['O', 'Q', 'D'] and is_clearly_zero_context(text, i):
            # R√µ r√†ng l√† s·ªë 0
            result += '0'
        elif char == 'I' and is_clearly_one_context(text, i):
            # R√µ r√†ng l√† s·ªë 1
            result += '1'
        elif char == 'S' and is_clearly_five_context(text, i):
            # S c√≥ th·ªÉ l√† 5
            result += '5'
        elif char == 'B' and is_clearly_eight_context(text, i):
            # B c√≥ th·ªÉ l√† 8
            result += '8'
        elif char == 'G' and is_clearly_six_context(text, i):
            # G c√≥ th·ªÉ l√† 6
            result += '6'
        else:
            # Gi·ªØ nguy√™n n·∫øu kh√¥ng ch·∫Øc ch·∫Øn
            result += char
    
    return result

def is_surrounded_by_numbers_context(text, pos):
    """Ki·ªÉm tra xem k√Ω t·ª± c√≥ b·ªã bao quanh b·ªüi context s·ªë kh√¥ng"""
    before = text[pos-1] if pos > 0 else ''
    after = text[pos+1] if pos < len(text)-1 else ''
    
    # N·∫øu tr∆∞·ªõc v√† sau ƒë·ªÅu l√† s·ªë ho·∫∑c k√Ω t·ª± gi·ªëng s·ªë
    return (before.isdigit() or before in ['O', 'Q', 'D']) and \
           (after.isdigit() or after in ['O', 'Q', 'D'])

def is_likely_zero_context(text, pos):
    """Ki·ªÉm tra context cho k√Ω t·ª± c√≥ th·ªÉ l√† s·ªë 0"""
    # N·∫øu xung quanh c√≥ nhi·ªÅu s·ªë
    surrounding = ""
    start = max(0, pos-2)
    end = min(len(text), pos+3)
    
    for i in range(start, end):
        if i != pos:
            surrounding += text[i]
    
    digit_count = sum(1 for c in surrounding if c.isdigit())
    return digit_count >= 2

def is_clearly_zero_context(text, pos):
    """Ki·ªÉm tra r√µ r√†ng l√† s·ªë 0 trong context s·ªë"""
    return has_digit_neighbors(text, pos, distance=1)

def is_clearly_one_context(text, pos):
    """Ki·ªÉm tra r√µ r√†ng l√† s·ªë 1"""
    return has_digit_neighbors(text, pos, distance=1)

def is_clearly_five_context(text, pos):
    """Ki·ªÉm tra r√µ r√†ng l√† s·ªë 5"""
    return has_digit_neighbors(text, pos, distance=2)

def is_clearly_eight_context(text, pos):
    """Ki·ªÉm tra r√µ r√†ng l√† s·ªë 8"""
    return has_digit_neighbors(text, pos, distance=1)

def is_clearly_six_context(text, pos):
    """Ki·ªÉm tra r√µ r√†ng l√† s·ªë 6"""
    return has_digit_neighbors(text, pos, distance=1)

def has_digit_neighbors(text, pos, distance=1):
    """Ki·ªÉm tra xem c√≥ s·ªë ·ªü g·∫ßn kh√¥ng"""
    for i in range(max(0, pos-distance), min(len(text), pos+distance+1)):
        if i != pos and text[i].isdigit():
            return True
    return False


def advanced_image_preprocessing(image):
    """Ti·ªÅn x·ª≠ l√Ω ·∫£nh n√¢ng cao cho OCR"""
    # Chuy·ªÉn sang grayscale n·∫øu c·∫ßn
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    # 1. Kh·ª≠ nhi·ªÖu
    if enable_denoise:
        gray = cv2.bilateralFilter(gray, 9, 75, 75)
    
    # 2. C√¢n b·∫±ng histogram adaptive
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    gray = clahe.apply(gray)
    
    # 3. Morphological operations ƒë·ªÉ l√†m s·∫°ch
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    gray = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)
    
    # 4. TƒÉng ƒë·ªô s·∫Øc n√©t
    if enable_sharpen:
        kernel_sharp = np.array([[-1,-1,-1],
                               [-1, 9,-1],
                               [-1,-1,-1]])
        gray = cv2.filter2D(gray, -1, kernel_sharp)
    
    # 5. Threshold adaptive ƒë·ªÉ t√°ch ch·ªØ v√† n·ªÅn
    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                  cv2.THRESH_BINARY, 11, 2)
    
    # 6. Th·ª≠ c·∫£ ·∫£nh g·ªëc v√† ·∫£nh ƒë·∫£o ng∆∞·ª£c
    binary_inv = cv2.bitwise_not(binary)
    
    return gray, binary, binary_inv

def order_points(pts):
    """S·∫Øp x·∫øp c√°c ƒëi·ªÉm theo th·ª© t·ª±: tr√™n-tr√°i, tr√™n-ph·∫£i, d∆∞·ªõi-ph·∫£i, d∆∞·ªõi-tr√°i"""
    rect = np.zeros((4, 2), dtype=np.float32)
    
    # T·ªïng t·ªça ƒë·ªô (x,y) nh·ªè nh·∫•t l√† ƒëi·ªÉm tr√™n-tr√°i
    # T·ªïng t·ªça ƒë·ªô (x,y) l·ªõn nh·∫•t l√† ƒëi·ªÉm d∆∞·ªõi-ph·∫£i
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    
    # Hi·ªáu t·ªça ƒë·ªô (x-y) nh·ªè nh·∫•t l√† ƒëi·ªÉm tr√™n-ph·∫£i
    # Hi·ªáu t·ªça ƒë·ªô (x-y) l·ªõn nh·∫•t l√† ƒëi·ªÉm d∆∞·ªõi-tr√°i
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    
    return rect

def four_point_transform(image, pts):
    """Th·ª±c hi·ªán bi·∫øn ƒë·ªïi ph·ªëi c·∫£nh 4 ƒëi·ªÉm"""
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    
    # T√≠nh chi·ªÅu r·ªông m·ªõi
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))
    
    # T√≠nh chi·ªÅu cao m·ªõi
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))
    
    # T·∫°o ma tr·∫≠n ƒëi·ªÉm ƒë√≠ch
    dst = np.array([
        [0, 0],
        [maxWidth - 1, 0],
        [maxWidth - 1, maxHeight - 1],
        [0, maxHeight - 1]
    ], dtype=np.float32)
    
    # T√≠nh ma tr·∫≠n bi·∫øn ƒë·ªïi v√† th·ª±c hi·ªán bi·∫øn ƒë·ªïi
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))
    
    return warped

def perform_multiple_ocr(image):
    """Th·ª±c hi·ªán OCR v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p kh√°c nhau v√† ch·ªçn k·∫øt qu·∫£ t·ªët nh·∫•t"""
    results = []
    
    # Resize ·∫£nh
    height, width = image.shape[:2]
    if height < 50 or width < 150:
        scale = max(50/height, 150/width)
        new_width = int(width * scale * resize_factor)
        new_height = int(height * scale * resize_factor)
        resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
    else:
        resized = cv2.resize(image, None, fx=resize_factor, fy=resize_factor, interpolation=cv2.INTER_CUBIC)
    
    # Ti·ªÅn x·ª≠ l√Ω ·∫£nh
    gray, binary, binary_inv = advanced_image_preprocessing(resized)
    
    # Danh s√°ch c√°c ·∫£nh ƒë·ªÉ th·ª≠ OCR
    images_to_try = [
        ("original", resized),
        ("gray", gray),
        ("binary", binary),
        ("binary_inverted", binary_inv)
    ]
    
    # Th·ª≠ OCR v·ªõi c√°c c·∫•u h√¨nh kh√°c nhau
    ocr_configs = [
        # C·∫•u h√¨nh 1: Standard
        {'allowlist': '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ-', 'width_ths': 0.7, 'height_ths': 0.7},
        # C·∫•u h√¨nh 2: Relaxed thresholds
        {'allowlist': '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ-', 'width_ths': 0.5, 'height_ths': 0.5},
        # C·∫•u h√¨nh 3: Character-based
        {'allowlist': '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ-', 'width_ths': 0.3, 'height_ths': 0.3, 'paragraph': False},
    ]
    
    for img_name, img in images_to_try:
        for config in ocr_configs:
            try:
                ocr_result = reader.readtext(img, **config)
                
                if ocr_result:
                    # T√≠nh confidence trung b√¨nh
                    confidences = [conf for (_, _, conf) in ocr_result]
                    avg_confidence = sum(confidences) / len(confidences)
                    
                    # Gh√©p text
                    raw_text = " ".join([text for (_, text, _) in ocr_result])
                    cleaned_text = clean_license_plate_text(raw_text)
                    
                    if cleaned_text and avg_confidence >= (ocr_confidence_threshold / 100):
                        results.append({
                            'text': cleaned_text,
                            'raw_text': raw_text,
                            'confidence': avg_confidence,
                            'method': f"{img_name}",
                            'length': len(cleaned_text.replace('-', ''))
                        })
            except Exception as e:
                continue
    
    if not results:
        return "", 0, "No result"
    
    # S·∫Øp x·∫øp k·∫øt qu·∫£ theo confidence v√† ƒë·ªô d√†i h·ª£p l√Ω (6-10 k√Ω t·ª± cho bi·ªÉn s·ªë VN)
    def score_result(result):
        base_score = result['confidence']
        length = result['length']
        
        # Bonus cho ƒë·ªô d√†i h·ª£p l√Ω c·ªßa bi·ªÉn s·ªë Vi·ªát Nam
        if 6 <= length <= 10:
            base_score += 0.1
        elif 5 <= length <= 11:
            base_score += 0.05
        else:
            base_score -= 0.1
            
        return base_score
    
    results.sort(key=score_result, reverse=True)
    best_result = results[0]
    
    return best_result['text'], best_result['confidence'] * 100, best_result['method']

def process_image(image):
    """Process image and return results"""
    # Convert PIL Image to numpy array
    image_np = np.array(image)
    # Convert RGB to BGR (OpenCV format)
    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    
    # Detect license plates
    results = model(image_bgr)
    boxes = results[0].boxes.xyxy.cpu().numpy()
    confidences = results[0].boxes.conf.cpu().numpy()
    
    # Process each detected plate
    plates = []
    for box, conf in zip(boxes, confidences):
        if conf * 100 >= confidence_threshold:
            x1, y1, x2, y2 = map(int, box)
            
            # C·∫Øt bi·ªÉn s·ªë xe t·ª´ ·∫£nh g·ªëc v·ªõi padding
            padding = 5
            x1_pad = max(0, x1 - padding)
            y1_pad = max(0, y1 - padding)
            x2_pad = min(image_bgr.shape[1], x2 + padding)
            y2_pad = min(image_bgr.shape[0], y2 + padding)
            
            cropped_plate = image_bgr[y1_pad:y2_pad, x1_pad:x2_pad]
            
            # Th·ª±c hi·ªán ph·ªëi c·∫£nh 4 g√≥c
            corners = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]], dtype=np.float32)
            warped_plate = four_point_transform(image_bgr, corners)
            
            # Th·ª±c hi·ªán OCR v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p
            plate_text, ocr_confidence, ocr_method = perform_multiple_ocr(warped_plate)
            
            # V·∫Ω box v√† text l√™n ·∫£nh g·ªëc
            cv2.rectangle(image_bgr, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # T·∫°o ·∫£nh hi·ªÉn th·ªã
            display_image = cv2.resize(warped_plate, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
            display_image_rgb = cv2.cvtColor(display_image, cv2.COLOR_BGR2RGB)
            
            plates.append({
                'text': plate_text,
                'box': (x1, y1, x2, y2),
                'image': display_image_rgb,
                'cropped_image': cv2.cvtColor(cropped_plate, cv2.COLOR_BGR2RGB),
                'detect_confidence': conf * 100,
                'ocr_confidence': ocr_confidence,
                'ocr_method': ocr_method
            })
    
    # Convert BGR back to RGB for display
    result_image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    return result_image, plates

# ================================
# üì§ FILE UPLOAD SECTION
# ================================
st.markdown("## üì§ T·∫£i l√™n ·∫£nh")

uploaded_file = st.file_uploader(
    "Ch·ªçn ·∫£nh ƒë·ªÉ ph√¢n t√≠ch",
    type=["jpg", "jpeg", "png"],
    help="H·ªó tr·ª£: JPG, PNG. K√≠ch th∆∞·ªõc t·ªëi ƒëa: 10MB"
)

if uploaded_file is not None:
    # Display original image
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### üñºÔ∏è ·∫¢nh g·ªëc")
        image = Image.open(uploaded_file)
        st.image(image, caption='·∫¢nh ƒë√£ t·∫£i l√™n', use_container_width=True)
        
        # Image info
        width, height = image.size
        st.info(f"üìê K√≠ch th∆∞·ªõc: {width} x {height} pixels")
    
    with col2:
        st.markdown("### üîç K·∫øt qu·∫£ ph√¢n t√≠ch")
        
        if st.button("üöÄ B·∫Øt ƒë·∫ßu ph√¢n t√≠ch", type="primary", use_container_width=True):
            with st.spinner('ü§ñ AI ƒëang ph√¢n t√≠ch...'):
                try:
                    # Process image
                    result_image, plates = process_image(image)
                    
                    # Display result image
                    st.image(result_image, caption='K·∫øt qu·∫£ nh·∫≠n di·ªán', use_container_width=True)
                    
                    # Display detected plates
                    if plates:
                        st.success(f"‚úÖ ƒê√£ ph√°t hi·ªán {len(plates)} bi·ªÉn s·ªë xe!")
                        
                        for i, plate in enumerate(plates, 1):
                            # T·∫°o 3 c·ªôt ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£
                            plate_col1, plate_col2, plate_col3 = st.columns(3)
                            
                            with plate_col1:
                                st.image(plate['cropped_image'], caption=f'Bi·ªÉn s·ªë #{i} (·∫¢nh c·∫Øt)', use_container_width=True)
                            
                            with plate_col2:
                                st.image(plate['image'], caption=f'Bi·ªÉn s·ªë #{i} (·∫¢nh x·ª≠ l√Ω)', use_container_width=True)
                            
                            with plate_col3:
                                # X√°c ƒë·ªãnh m√†u d·ª±a tr√™n confidence
                                if plate['ocr_confidence'] >= 80:
                                    confidence_color = "#4CAF50"  # Xanh l√°
                                elif plate['ocr_confidence'] >= 60:
                                    confidence_color = "#FF9800"  # Cam
                                else:
                                    confidence_color = "#F44336"  # ƒê·ªè
                                
                                st.markdown(f"""
                                <div style="background: linear-gradient(135deg, {confidence_color} 0%, #764ba2 100%); padding: 1.5rem; border-radius: 10px; color: white; text-align: center; margin: 1rem 0; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
                                    <h3>Bi·ªÉn s·ªë #{i}</h3>
                                    <h2 style="font-size: 2em; margin: 10px 0; font-weight: bold;">{plate['text'] if plate['text'] else 'Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c'}</h2>
                                    <div style="margin: 15px 0;">
                                        <p style="font-size: 1.1em;">üìä ƒê·ªô tin c·∫≠y:</p>
                                        <p>ü§ñ Ph√°t hi·ªán: {plate['detect_confidence']:.1f}%</p>
                                        <p>üìù OCR: {plate['ocr_confidence']:.1f}%</p>
                                        <p style="font-size: 0.9em;">üîß Ph∆∞∆°ng ph√°p: {plate['ocr_method']}</p>
                                    </div>
                                </div>
                                """, unsafe_allow_html=True)
                            
                            if show_details:
                                with st.expander(f"Chi ti·∫øt k·ªπ thu·∫≠t bi·ªÉn s·ªë #{i}"):
                                    st.write(f"**T·ªça ƒë·ªô:** {plate['box']}")
                                    st.write(f"**Confidence ph√°t hi·ªán:** {plate['detect_confidence']:.2f}%")
                                    st.write(f"**Confidence OCR:** {plate['ocr_confidence']:.2f}%")
                                    st.write(f"**Ph∆∞∆°ng ph√°p OCR:** {plate['ocr_method']}")
                                    st.write(f"**ƒê·ªô d√†i text:** {len(plate['text'])} k√Ω t·ª±")
                                
                                st.markdown("---")
                    else:
                        st.warning(f"‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán bi·ªÉn s·ªë xe n√†o v·ªõi ng∆∞·ª°ng tin c·∫≠y {confidence_threshold}%!")
                        st.info("üí° **G·ª£i √Ω:** Th·ª≠ gi·∫£m ng∆∞·ª°ng tin c·∫≠y ho·∫∑c upload ·∫£nh c√≥ ch·∫•t l∆∞·ª£ng t·ªët h∆°n")
                    
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi ph√¢n t√≠ch: {str(e)}")
                    st.error("üîß H√£y th·ª≠ v·ªõi ·∫£nh kh√°c ho·∫∑c ƒëi·ªÅu ch·ªânh c√°c tham s·ªë")

# ================================
# üìä FOOTER STATISTICS
# ================================
st.markdown("---")
st.markdown("### üìà Th·ªëng k√™ h·ªá th·ªëng")

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("ü§ñ M√¥ h√¨nh", "YOLOv8 + EasyOCR")

with col2:
    st.metric("üéØ ƒê·ªô ch√≠nh x√°c", ">90%")

with col3:
    st.metric("‚ö° T·ªëc ƒë·ªô x·ª≠ l√Ω", "~2s/·∫£nh")

with col4:
    st.metric("üîß Ph∆∞∆°ng ph√°p OCR", "Multi-method")

# Add footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 2rem;'>
    <p>üöó <strong>Nh·∫≠n di·ªán bi·ªÉn s·ªë xe th√¥ng minh</strong> - ƒê∆∞·ª£c ph√°t tri·ªÉn v·ªõi ‚ù§Ô∏è b·∫±ng Streamlit & YOLOv8</p>
    <p>ü§ñ Nh·∫≠n di·ªán bi·ªÉn s·ªë ch√≠nh x√°c ‚Ä¢ üìä X·ª≠ l√Ω ·∫£nh ƒëa ph∆∞∆°ng ph√°p ‚Ä¢ üîí B·∫£o m·∫≠t d·ªØ li·ªáu</p>
    <p style="font-size: 0.9em; margin-top: 1rem;">
        <strong>C·∫£i ti·∫øn m·ªõi:</strong> OCR ƒëa ph∆∞∆°ng ph√°p ‚Ä¢ Ti·ªÅn x·ª≠ l√Ω ·∫£nh n√¢ng cao ‚Ä¢ L√†m s·∫°ch text th√¥ng minh
    </p>
</div>
""", unsafe_allow_html=True)